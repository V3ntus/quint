{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/poloniki/.pyenv/versions/3.8.12/envs/quint/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../quint/data/results/Short.txt') as f:\n",
    "    doc = f.readlines()\n",
    "    \n",
    "doc = doc[0].replace(\"?\", \". \")\n",
    "sentences = doc.split('. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A =  embeddings\n",
    "# A_sparse = sparse.csr_matrix(A)\n",
    "\n",
    "# similarities = cosine_similarity(A_sparse)\n",
    "# # print('pairwise dense output:\\n {}\\n'.format(similarities))\n",
    "\n",
    "# #also can output sparse matrices\n",
    "# similarities_sparse = cosine_similarity(A_sparse,dense_output=False)\n",
    "# # print('pairwise sparse output:\\n {}\\n'.format(similarities_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A =  embeddings[0:0+50]\n",
    "# A_sparse = sparse.csr_matrix(A)\n",
    "# similarities = cosine_similarity(A_sparse)\n",
    "# average_sim = similarities.mean(axis=1)\n",
    "# best_sentence = list(average_sim).index(average_sim.max())\n",
    "# similarities_sparse = cosine_similarity(A_sparse,dense_output=False)\n",
    "# print('pairwise sparse output:\\n {}\\n'.format(similarities_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_sim = np.round(similarities.mean(axis=1),2)\n",
    "# np.round(average_sim,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['sentence'] = sentences[:-1]\n",
    "\n",
    "df['len'] = df['sentence'].apply(lambda x: len(x))\n",
    "df['cum'] = df['len'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = round(df['cum'].sum() / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sentences = []\n",
    "steps = range(0, df.cum.max() + steps, steps*2)\n",
    "for each in range(len(steps)-1):\n",
    "    temp_df = df.loc[(df.cum > steps[each])&(df.cum < steps[each+1])]\n",
    "    indexes = temp_df.index\n",
    "    A =  embeddings[indexes[0]:indexes[-1]+1]\n",
    "    A_sparse = sparse.csr_matrix(A)\n",
    "    similarities = cosine_similarity(A_sparse)\n",
    "    \n",
    "    average_sim = list(np.round(similarities.mean(axis=1),2))\n",
    "    min_score =np.min(average_sim)\n",
    "    max_score = np.max(average_sim)\n",
    "    best_sentence = [i for i, x in enumerate(average_sim) if (x > max_score-0.02)]\n",
    "    for every in best_sentence:\n",
    "        best_sentences.append(temp_df.iloc[every].sentence)\n",
    "        \n",
    "best_sentences = [each for each in best_sentences if len(each.split(' '))> 5]\n",
    "df['highlight'] = df['sentence'].apply(lambda x: x in best_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" They're taking money from the Russians\",\n",
       " 'And of course the answer is no but I do this for a living like I speak',\n",
       " 'Do you want to do that']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>len</th>\n",
       "      <th>cum</th>\n",
       "      <th>highlight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They're taking money from the Russians</td>\n",
       "      <td>39</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And of course the answer is no but I do this f...</td>\n",
       "      <td>70</td>\n",
       "      <td>170</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Do you want to do that</td>\n",
       "      <td>22</td>\n",
       "      <td>591</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  len  cum  highlight\n",
       "1              They're taking money from the Russians   39  100       True\n",
       "2   And of course the answer is no but I do this f...   70  170       True\n",
       "10                             Do you want to do that   22  591       True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.highlight==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 11:39:36.185015: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-05 11:39:36.241424: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-05 11:39:36.241438: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-05 11:39:38.160082: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-05 11:39:38.160120: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-05 11:39:38.160148: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-533EO63): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object Language.pipe at 0x7fe4f2d02ba0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp.pipe('Here am i Nikita')\n",
    "# mentioned = [ent.lemma_ for ent in doc.ents if ent.label_ == 'PERSON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You know people are like how do you live and things like that. \u001b[41m\u001b[37m They're taking money from the Russians. \u001b[0m\u001b[41m\u001b[37mAnd of course the answer is no but I do this for a living like I speak. \u001b[0mI don't have a \u001b[1mYouTube\u001b[0m channel that where it's you know, I'm \u001b[1mJoe\u001b[0m \u001b[1mRogan,\u001b[0m but I give speeches at universities and things like that. I do a lot of interviews and so we're recording now right on set up cool. Is it possible that you could do a \u001b[1mYouTube\u001b[0m channel.  Would that work.  If yeah, like I I mean if you introduce me so like I get followers. Yeah, we could do that. I'm all in that that could absolutely happen. \u001b[41m\u001b[37mDo you want to do that. \u001b[0m Is it something you want to do. \n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def preprocessing(sentence):\n",
    "\n",
    "    sentence = ''.join([each for each in sentence if each not in string.punctuation])\n",
    "\n",
    "    return sentence\n",
    "def get_persons(text):\n",
    "    for doc in nlp.pipe([text]):\n",
    "        mentioned = [ent.lemma_ for ent in doc.ents if ent.label_ in ['PERSON', 'PRODUCT', 'ORG', 'GPE', 'MONEY', 'CARDINAL']]\n",
    "    return mentioned\n",
    "    \n",
    "df['names'] = df.sentence.apply(get_persons)\n",
    "\n",
    "from termcolor import colored\n",
    "from spacy import displacy\n",
    "\n",
    "text = ''\n",
    "for num, each in enumerate(df['sentence']):\n",
    "    #Bold words\n",
    "    to_bold = df['names'].iloc[num]\n",
    "    if len(to_bold)>0:\n",
    "        to_unpack = [i.split(' ', 1) for i in to_bold]\n",
    "        flat_list = [item for sublist in to_unpack for item in sublist]\n",
    "        each = \" \".join(f'\\033[1m{t}\\033[0m' if (preprocessing(t) in flat_list) & (preprocessing(t).lower() != 'the')  else t for t in each.split())\n",
    "        #print(flat_list, each, each.split())\n",
    "    # Highlight best sentence if it is there \n",
    "    if df['highlight'].iloc[num] == True:\n",
    "        text+=colored(f'{each}. ','white','on_red')\n",
    "    else:\n",
    "        text+=f'{each}. '\n",
    "    \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy import displacy\n",
    "\n",
    "# doc = nlp(text)\n",
    "# options = {\"ents\": ['PERSON', 'PRODUCT', 'ORG', 'GPE', 'MONEY', 'CARDINAL ']}\n",
    "\n",
    "# displacy.serve(doc, style=\"ent\",options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pairwise sparse output:\n",
      "   (0, 104)\t-0.02589854\n",
      "  (0, 103)\t0.021266721\n",
      "  (0, 102)\t0.0074429987\n",
      "  (0, 101)\t0.005696579\n",
      "  (0, 100)\t0.0046391385\n",
      "  (0, 99)\t0.08170297\n",
      "  (0, 98)\t0.047602687\n",
      "  (0, 97)\t0.08170297\n",
      "  (0, 96)\t-0.016100569\n",
      "  (0, 95)\t0.04104335\n",
      "  (0, 94)\t0.052055288\n",
      "  (0, 93)\t0.040341523\n",
      "  (0, 92)\t0.28603432\n",
      "  (0, 91)\t0.12118529\n",
      "  (0, 90)\t0.1056238\n",
      "  (0, 89)\t0.12997746\n",
      "  (0, 88)\t0.09192037\n",
      "  (0, 87)\t0.0020450838\n",
      "  (0, 86)\t0.052878164\n",
      "  (0, 85)\t-0.0083633885\n",
      "  (0, 84)\t0.035215165\n",
      "  (0, 83)\t-0.001178159\n",
      "  (0, 82)\t0.105132595\n",
      "  (0, 81)\t0.17433318\n",
      "  (0, 80)\t0.21162403\n",
      "  :\t:\n",
      "  (104, 24)\t0.03408325\n",
      "  (104, 23)\t-0.07958412\n",
      "  (104, 22)\t-0.02097783\n",
      "  (104, 21)\t0.06452103\n",
      "  (104, 20)\t0.16395216\n",
      "  (104, 19)\t0.16861263\n",
      "  (104, 18)\t0.058462113\n",
      "  (104, 17)\t0.12590262\n",
      "  (104, 16)\t0.105187334\n",
      "  (104, 15)\t0.16208836\n",
      "  (104, 14)\t0.06427233\n",
      "  (104, 13)\t-0.074408196\n",
      "  (104, 12)\t-0.0098676905\n",
      "  (104, 11)\t0.07735178\n",
      "  (104, 10)\t0.037142176\n",
      "  (104, 9)\t-0.0681082\n",
      "  (104, 8)\t-0.01745296\n",
      "  (104, 7)\t0.0289875\n",
      "  (104, 6)\t-0.04575046\n",
      "  (104, 5)\t0.005130356\n",
      "  (104, 4)\t-0.032000545\n",
      "  (104, 3)\t0.17408757\n",
      "  (104, 2)\t0.0021078102\n",
      "  (104, 1)\t-0.032461327\n",
      "  (104, 0)\t-0.02589854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "similarities_sparse = cosine_similarity(A_sparse,dense_output=False)\n",
    "print('pairwise sparse output:\\n {}\\n'.format(similarities_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "8d98f679e85918cf6df43a016c8cf832b102b395abdc24b4f6327e5d97b9a7f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
